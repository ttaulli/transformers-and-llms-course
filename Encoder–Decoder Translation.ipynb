{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f3b73930-c9f2-4210-ba89-d7641f185766",
   "metadata": {},
   "source": [
    "# Encoder-Decoder Translation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d74cf059-b603-43a1-9295-dd2fde29a264",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install transformers sentencepiece --quiet\n",
    "\n",
    "# Mac install in terminal - conda install pytorch=2.6 torchvision torchaudio -c pytorch\n",
    "\n",
    "# Windows install in terminal - conda install pytorch=2.6 torchvision torchaudio cpuonly -c pytorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7a0e304e-6b20-4ecc-bc4a-1804246d18f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import pipeline\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9fc07341-7ea4-433e-b7ea-b6dc040db06b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.12/site-packages/transformers/models/marian/tokenization_marian.py:175: UserWarning: Recommended: pip install sacremoses.\n",
      "  warnings.warn(\"Recommended: pip install sacremoses.\")\n",
      "Device set to use cpu\n"
     ]
    }
   ],
   "source": [
    "translator = pipeline(\"translation\", model=\"Helsinki-NLP/opus-mt-en-fr\")\n",
    "text = \"The riverbank was covered with wildflowers.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b5c35c57-5db3-45ec-b5f4-8b85b889ce43",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['output_hidden_states']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoModelForSeq2SeqLM, AutoTokenizer\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"Helsinki-NLP/opus-mt-en-fr\")\n",
    "model = AutoModelForSeq2SeqLM.from_pretrained(\n",
    "    \"Helsinki-NLP/opus-mt-en-fr\",\n",
    "    output_hidden_states=True\n",
    ")\n",
    "\n",
    "inputs = tokenizer(text, return_tensors=\"pt\")\n",
    "\n",
    "# Get encoder hidden states only\n",
    "encoder_outputs = model.model.encoder(\n",
    "    input_ids=inputs[\"input_ids\"],\n",
    "    attention_mask=inputs[\"attention_mask\"],\n",
    "    output_hidden_states=True,\n",
    "    return_dict=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9872523a-2277-460c-a66b-13c30d3d4535",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BaseModelOutput(last_hidden_state=tensor([[[-0.2102, -0.2068, -0.0811,  ...,  0.1718,  0.3154, -0.0091],\n",
       "         [ 0.2529, -0.2698, -0.4728,  ...,  0.2907, -0.4666,  0.1155],\n",
       "         [-0.2714, -0.0846, -0.1218,  ...,  0.0221, -0.1134, -0.0924],\n",
       "         ...,\n",
       "         [-0.1508, -0.1977,  0.0820,  ...,  0.2332,  0.0769,  0.4241],\n",
       "         [ 0.0443,  0.0423,  0.1285,  ...,  0.0590, -0.1956,  0.1630],\n",
       "         [-0.0710, -0.0120, -0.0436,  ...,  0.0213, -0.1536,  0.0067]]],\n",
       "       grad_fn=<NativeLayerNormBackward0>), hidden_states=(tensor([[[-0.2734, -0.3387,  0.0982,  ..., -0.1762,  0.6778, -1.2438],\n",
       "         [ 0.7630,  0.4338,  0.1135,  ...,  0.8364, -0.4221,  1.0364],\n",
       "         [ 1.8897,  1.0854,  0.7504,  ..., -0.2146,  0.1899,  0.8723],\n",
       "         ...,\n",
       "         [ 1.6101,  0.5756,  0.9446,  ...,  0.2838,  0.4086,  0.8997],\n",
       "         [ 0.3730,  0.5614,  0.7983,  ...,  0.9304, -0.1663,  0.5690],\n",
       "         [-0.5201, -0.0647, -0.2032,  ...,  1.1537,  0.0423,  0.2740]]],\n",
       "       grad_fn=<AddBackward0>), tensor([[[-0.6626, -0.3359, -0.3650,  ..., -0.4439,  0.6700, -0.9902],\n",
       "         [ 0.7335, -0.0978, -0.9326,  ...,  0.4803, -1.1347,  0.2101],\n",
       "         [ 0.4605,  0.5108,  0.8404,  ..., -0.4653, -0.1546, -0.2770],\n",
       "         ...,\n",
       "         [ 0.6756,  0.4444,  1.1255,  ...,  0.0421,  0.3865,  1.1648],\n",
       "         [ 0.3214,  0.6205,  1.0277,  ..., -0.1487, -0.4671, -0.0134],\n",
       "         [-0.4695, -0.3000, -0.0100,  ..., -0.0439,  0.0065, -0.1632]]],\n",
       "       grad_fn=<NativeLayerNormBackward0>), tensor([[[-0.4874, -0.5465, -1.0749,  ..., -0.2084,  0.3961, -0.7352],\n",
       "         [ 0.6052, -0.4759, -1.2340,  ..., -0.1293, -0.6410,  0.1722],\n",
       "         [ 0.2583,  0.1746,  0.7039,  ..., -0.5669, -0.1034, -0.2886],\n",
       "         ...,\n",
       "         [ 0.5718,  0.5964,  1.0131,  ..., -0.0299,  0.0934,  1.0835],\n",
       "         [ 0.6268, -0.0024,  0.4981,  ..., -0.1242, -0.5838,  0.2739],\n",
       "         [-0.1501, -0.1319, -0.0258,  ..., -0.0818,  0.0170, -0.0689]]],\n",
       "       grad_fn=<NativeLayerNormBackward0>), tensor([[[-0.3349, -0.3027, -0.3635,  ..., -0.0142,  0.5795, -0.5287],\n",
       "         [ 0.4843, -0.4540, -0.9745,  ...,  0.0053, -0.6999,  0.3620],\n",
       "         [-0.0640, -0.2355,  0.2188,  ...,  0.0030,  0.1114, -0.3340],\n",
       "         ...,\n",
       "         [ 0.6868, -0.1879,  0.7185,  ..., -0.3501,  0.1516,  1.2031],\n",
       "         [ 0.3279, -0.1059,  0.7647,  ..., -0.1566, -0.5023,  0.4522],\n",
       "         [-0.0474, -0.0821,  0.1060,  ...,  0.0325, -0.0565,  0.0084]]],\n",
       "       grad_fn=<NativeLayerNormBackward0>), tensor([[[-0.0453, -0.4649, -0.2433,  ...,  0.0086,  0.7335, -0.4168],\n",
       "         [ 1.0617, -0.5528, -1.5667,  ..., -0.0035, -0.7679,  0.0117],\n",
       "         [ 0.0334, -0.3796,  0.1724,  ..., -0.3382,  0.3617, -0.7536],\n",
       "         ...,\n",
       "         [ 0.4991, -0.5248,  0.6170,  ..., -0.5666,  0.7506,  0.9618],\n",
       "         [ 0.2743,  0.1134,  0.6911,  ..., -0.0365, -0.4345,  0.3062],\n",
       "         [-0.1332, -0.2252,  0.1020,  ...,  0.0147, -0.0337,  0.1576]]],\n",
       "       grad_fn=<NativeLayerNormBackward0>), tensor([[[-0.4127, -0.6140, -0.1403,  ..., -0.1052,  0.8167, -0.1842],\n",
       "         [ 0.6513, -0.8610, -1.1613,  ...,  0.2069, -0.6942,  0.0193],\n",
       "         [-0.5964, -0.1830, -0.0302,  ..., -0.3160,  0.3734, -0.0739],\n",
       "         ...,\n",
       "         [-0.3085, -0.4868,  0.3707,  ..., -0.0954,  0.7572,  0.7411],\n",
       "         [ 0.0600,  0.3082,  0.6082,  ...,  0.3450, -0.3331,  0.2804],\n",
       "         [-0.1666, -0.0609,  0.0415,  ...,  0.0903, -0.1836, -0.0979]]],\n",
       "       grad_fn=<NativeLayerNormBackward0>), tensor([[[-0.2102, -0.2068, -0.0811,  ...,  0.1718,  0.3154, -0.0091],\n",
       "         [ 0.2529, -0.2698, -0.4728,  ...,  0.2907, -0.4666,  0.1155],\n",
       "         [-0.2714, -0.0846, -0.1218,  ...,  0.0221, -0.1134, -0.0924],\n",
       "         ...,\n",
       "         [-0.1508, -0.1977,  0.0820,  ...,  0.2332,  0.0769,  0.4241],\n",
       "         [ 0.0443,  0.0423,  0.1285,  ...,  0.0590, -0.1956,  0.1630],\n",
       "         [-0.0710, -0.0120, -0.0436,  ...,  0.0213, -0.1536,  0.0067]]],\n",
       "       grad_fn=<NativeLayerNormBackward0>)), attentions=None)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoder_outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fffbb177-5d33-4083-8ee7-5ec3d17aa13e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 torch.Size([1, 11, 512])\n",
      "1 torch.Size([1, 11, 512])\n",
      "2 torch.Size([1, 11, 512])\n",
      "3 torch.Size([1, 11, 512])\n",
      "4 torch.Size([1, 11, 512])\n",
      "5 torch.Size([1, 11, 512])\n",
      "6 torch.Size([1, 11, 512])\n"
     ]
    }
   ],
   "source": [
    "for i, layer in enumerate(encoder_outputs.hidden_states):\n",
    "    print(i, layer.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6c0eee3-0489-4ed2-a3df-8ee753193630",
   "metadata": {},
   "outputs": [],
   "source": [
    "translated_tokens = model.generate(\n",
    "    inputs[\"input_ids\"],\n",
    "    max_length=40,\n",
    "    num_beams=4,\n",
    "    early_stopping=True\n",
    ")\n",
    "\n",
    "print(tokenizer.decode(translated_tokens[0], skip_special_tokens=True))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5aa362a0-2c70-4c03-b3db-5e9ff6452bab",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
