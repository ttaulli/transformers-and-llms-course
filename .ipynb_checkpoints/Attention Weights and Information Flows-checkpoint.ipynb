{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "71e03a14-4504-4a9a-9dd5-a77911f2f7e5",
   "metadata": {},
   "source": [
    "# Demo - Attention Weights and Information Flows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32d8a3db-1663-406f-90dc-335a05aad8dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8131b24-1b6e-45cc-ad4d-8c228bd6a6a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokens = [\"the\", \"doctor\", \"said\", \"she\", \"would\", \"return\"]\n",
    "\n",
    "# Raw dot-product scores (Query · Key)\n",
    "# Imagine \"she\" is the query token\n",
    "raw_scores = torch.tensor([\n",
    "    1.20,  # the\n",
    "    1.35,  # doctor\n",
    "    1.10,  # said\n",
    "    1.50,  # she\n",
    "    1.25,  # would\n",
    "    1.15   # return\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb3a8c91-3f3f-45f0-99c7-cf08c9fc065b",
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_df = pd.DataFrame({\n",
    "    \"Token\": tokens,\n",
    "    \"Raw Q·K Score\": raw_scores.numpy()\n",
    "}).sort_values(\"Raw Q·K Score\", ascending=False)\n",
    "\n",
    "raw_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2542570-0cb2-44d0-a7cd-0e3c0f107b58",
   "metadata": {},
   "outputs": [],
   "source": [
    "attention_weights = F.softmax(raw_scores, dim=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bd362c3-8016-4be5-9128-1329ac687e5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "comparison_df = pd.DataFrame({\n",
    "    \"Token\": tokens,\n",
    "    \"Raw Q·K Score\": raw_scores.numpy(),\n",
    "    \"Attention Weight\": attention_weights.detach().numpy()\n",
    "}).sort_values(\"Attention Weight\", ascending=False)\n",
    "\n",
    "comparison_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1a3ed2f-8274-4e2f-93b5-8a45476827bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(1, 2, figsize=(12, 4))\n",
    "\n",
    "# Raw scores\n",
    "axes[0].bar(tokens, raw_scores)\n",
    "axes[0].set_title(\"Raw Query·Key Scores\")\n",
    "axes[0].set_ylabel(\"Score\")\n",
    "axes[0].tick_params(axis='x', rotation=45)\n",
    "\n",
    "# Softmax weights\n",
    "axes[1].bar(tokens, attention_weights)\n",
    "axes[1].set_title(\"Attention Weights After Softmax\")\n",
    "axes[1].set_ylabel(\"Weight\")\n",
    "axes[1].tick_params(axis='x', rotation=45)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f950b05a-d0f1-4163-bc9a-74dd4c2031ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "flow_df = comparison_df.copy()\n",
    "flow_df[\"Percent of Information\"] = flow_df[\"Attention Weight\"] * 100\n",
    "\n",
    "flow_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a34c6fec-67ed-444a-a941-7778944bb72c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
